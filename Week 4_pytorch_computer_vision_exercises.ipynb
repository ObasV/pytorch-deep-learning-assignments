{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vex99np2wFVt"
      },
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/). \n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA). \n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "17dd5453-9639-4b01-aa18-7ddbfd5c3253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Apr 16 03:23:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "9c150c50-a092-4f34-9d33-b45247fb080d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSFX7tc1w-en"
      },
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "outputs": [],
      "source": [
        "# Health: Used in the diagnosis of diseases, such as cancer, alhezimer disease, \n",
        "\n",
        "# Transport: For the development of self driven vehicle, warehouse haulage robots\n",
        "\n",
        "# Identity management: Used in apps to detect emotions, age, facial features and other biometric data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBK-WI6YxDYa"
      },
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "outputs": [],
      "source": [
        "# Overfitting occurs when a machine model is only perform well on the training data but not on test and other real-life data. \n",
        "# This could be because of small size of the trainning data or due to biases in the data collection, which does not represent the population distribution\n",
        "# The problem of Overfitting could be solved by collecting the train and test data using an appropriate sampling method or adding some noise to the data\n",
        "# so that it represents a real-life scenerio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeYFEqw8xK26"
      },
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. \n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "outputs": [],
      "source": [
        "#  1. Cross-Validation: Divide your training data into multiple subsets (folds). Train and evaluate your model on different combinations of these folds. \n",
        "#                       This provides a more robust estimate of the model's performance\n",
        "\n",
        "# Feature Selection/Dimensionality Reduction: Select only the most relevant features for training, or reduce the number of features \n",
        "#                                               using techniques like Principal Component Analysis (PCA)\n",
        "\n",
        "# Data Augmentation:  How it works: Create new training samples by applying various transformations to existing data \n",
        "#                       (e.g., rotations, flips, crops for images; adding noise to audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKdEEFEqxM-8"
      },
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "outputs": [],
      "source": [
        "# done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvf-3pODxXYI"
      },
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SHjeuN81bHza"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms, datasets\n",
        "ToTensor = transforms.ToTensor\n",
        "\n",
        "# Download the MNIST dataset\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=False, transform=ToTensor())\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=False, transform=ToTensor())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZW-uAbxe_F"
      },
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QVFsYi1PbItE"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x900 with 15 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# len(train_dataset), len(test_dataset)\n",
        "# train_dataset.classes\n",
        "# train_dataset.class_to_idx\n",
        "\n",
        "# Display a sample image\n",
        "fig = plt.figure(figsize = (9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows*cols):\n",
        "    random_indx = torch.randint(0, len(train_dataset), size = [1]).item()\n",
        "    image, label = train_dataset[random_indx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(image.squeeze(), cmap = 'grey')\n",
        "    plt.title(label)\n",
        "    plt.axis(False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPDzW0wxhi3"
      },
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=32,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                              batch_size=32,\n",
        "                              shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 784])\n"
          ]
        }
      ],
      "source": [
        "# Items in the train dataloader\n",
        "train_feature_batch, train_label_batch = next(iter(train_dataloader))\n",
        "train_feature_batch.shape, train_label_batch.shape \n",
        "\n",
        "\n",
        "# Flatten an image\n",
        "flatten_model = torch.nn.Flatten()\n",
        "x = train_feature_batch[0]  # select a picture from a batch\n",
        "output = flatten_model(x)  #flatten an image\n",
        "\n",
        "print(output.shape)     #display the shape of a flattened image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCCVfXk5xjYS"
      },
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MNISTModel(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=784, out_features=10, bias=True)\n",
              "    (4): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch import nn\n",
        "\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape: int,\n",
        "                 hidden_units: int,\n",
        "                 output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=input_shape, out_features=output_shape),\n",
        "        nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.layer_stack(x)\n",
        "\n",
        "\n",
        "\n",
        "model_0 = MNISTModel(input_shape = 28*28, # value of the flattened layer\n",
        "                      hidden_units = 10, \n",
        "                      output_shape = 10).to(device)\n",
        "\n",
        "model_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_3zUr7xlhy"
      },
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MulticlassAccuracy()"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "acc_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "acc_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._dynamo' has no attribute 'config' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Hp\\Desktop\\Learnings\\Generative A I\\Udacity Gen A I program\\udacity_gen_ai\\Lib\\site-packages\\torch\\optim\\sgd.py:61\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable, fused)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov \u001b[38;5;129;01mand\u001b[39;00m (momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dampening \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_supports_amp_scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Hp\\Desktop\\Learnings\\Generative A I\\Udacity Gen A I program\\udacity_gen_ai\\Lib\\site-packages\\torch\\optim\\optimizer.py:371\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    368\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Hp\\Desktop\\Learnings\\Generative A I\\Udacity Gen A I program\\udacity_gen_ai\\Lib\\site-packages\\torch\\_compile.py:27\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[0;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n",
            "File \u001b[1;32mc:\\Users\\Hp\\Desktop\\Learnings\\Generative A I\\Udacity Gen A I program\\udacity_gen_ai\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
            "File \u001b[1;32mc:\\Users\\Hp\\Desktop\\Learnings\\Generative A I\\Udacity Gen A I program\\udacity_gen_ai\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:53\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     48\u001b[0m     _disable_current_modes,\n\u001b[0;32m     49\u001b[0m     is_in_torch_dispatch_mode,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CapturedTraceback, format_traceback_short\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     56\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[0;32m     57\u001b[0m     Instruction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     transform_code_object,\n\u001b[0;32m     61\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Hp\\Desktop\\Learnings\\Generative A I\\Udacity Gen A I program\\udacity_gen_ai\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:3218\u001b[0m\n\u001b[0;32m   3205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m   3206\u001b[0m     LEGACY_MOD_INLINELIST \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed.tensor._api\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed.tensor.device_mesh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed._composable.replicate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3217\u001b[0m     }\n\u001b[1;32m-> 3218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mskip_fsdp_hooks:\n\u001b[0;32m   3219\u001b[0m         LEGACY_MOD_INLINELIST\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed._composable.fsdp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3222\u001b[0m \u001b[38;5;66;03m# Force inline functions under these modules, even they are in *_SKIPLIST.\u001b[39;00m\n\u001b[0;32m   3223\u001b[0m \u001b[38;5;66;03m# We are using python module name instead of file or directory object to avoid circular dependency.\u001b[39;00m\n\u001b[0;32m   3224\u001b[0m \u001b[38;5;66;03m# Please keep this sorted alphabetically.\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'config' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 \n",
            "\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            " Train loss:  2.3234 | Test loss:  2.3227, Test acc:  0.10%\n",
            "Epoch: 1 \n",
            "\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            " Train loss:  2.3234 | Test loss:  2.3227, Test acc:  0.10%\n",
            "Epoch: 2 \n",
            "\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            " Train loss:  2.3234 | Test loss:  2.3227, Test acc:  0.10%\n",
            "Epoch: 3 \n",
            "\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            " Train loss:  2.3234 | Test loss:  2.3227, Test acc:  0.10%\n",
            "Epoch: 4 \n",
            "\n",
            "Looked at 0/60000 samples\n",
            "Looked at 12800/60000 samples\n",
            "Looked at 25600/60000 samples\n",
            "Looked at 38400/60000 samples\n",
            "Looked at 51200/60000 samples\n",
            "\n",
            " Train loss:  2.3234 | Test loss:  2.3227, Test acc:  0.10%\n",
            "Total time is: 90.8561208000001 seconds\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "    '''Prints differene between start and end time'''\n",
        "    total_time = end - start\n",
        "    print(f'Train time on {device}: {total_time} seconds')\n",
        "    return total_time\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "# set seed and start time\n",
        "torch.manual_seed(42)\n",
        "train_time_starts = timer()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch: {epoch} \\n')\n",
        "\n",
        "    # Training\n",
        "    train_loss = 0\n",
        "\n",
        "    # Loop through the training batches\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        model_0.train()\n",
        "\n",
        "        # forward pass\n",
        "        y_pred = model_0(X)\n",
        "\n",
        "        # calculate loss per batch\n",
        "        loss = loss_func(y_pred, y)\n",
        "        train_loss += loss\n",
        "\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # optimizer.step()\n",
        "\n",
        "        if batch % 400 == 0:\n",
        "            print(f'Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples')\n",
        "    \n",
        "    # Divide total train loss by lenght of train batch\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "\n",
        "    # Testing\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_0.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X_test, y_test in test_dataloader:\n",
        "            # forward pass\n",
        "            test_pred = model_0(X_test)\n",
        "\n",
        "            # Calculate loss accumulatively\n",
        "            test_loss += loss_func(test_pred, y_test)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            test_acc += acc_fn(test_pred.argmax(dim = 1), y_test)\n",
        "\n",
        "        # Calculate the test loss average per batch\n",
        "        test_loss /= len(test_dataloader)\n",
        "\n",
        "        # Calculate the test accuracy average per batch\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    # print out what is happening\n",
        "    print(f'\\n Train loss: {train_loss: .4f} | Test loss: {test_loss: .4f}, Test acc: {test_acc: .2f}%')\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end = timer()\n",
        "total_train_time_model  = train_time_end - train_time_starts\n",
        "\n",
        "print(f'Total time is: {total_train_time_model} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1CsHhPpxp1w"
      },
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQwzqlBWxrpG"
      },
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6bDhoWxt2y"
      },
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-0.4691, -0.4745, -0.1707,  ..., -0.0473, -0.2005, -0.1244],\n",
              "          [-0.5702, -0.3319, -0.1823,  ..., -0.2368, -0.1629, -0.4790],\n",
              "          [-0.3472, -0.3907, -0.5119,  ..., -0.4424, -0.3473, -0.1770],\n",
              "          ...,\n",
              "          [-0.7766, -0.2905, -0.2164,  ..., -0.4766, -0.0298, -0.2621],\n",
              "          [-0.3300, -0.1676, -0.2699,  ..., -0.0024, -0.5179, -0.3875],\n",
              "          [-0.1014, -0.3030, -0.3163,  ..., -0.2974, -0.5224, -0.4214]],\n",
              "\n",
              "         [[-0.3597, -0.4177, -0.2049,  ..., -0.2899, -0.3697, -0.5444],\n",
              "          [-0.3854, -0.4285, -0.5842,  ..., -0.6162, -0.5806, -0.2415],\n",
              "          [-0.6971, -0.5213, -0.4129,  ..., -0.4445, -0.5363, -0.2580],\n",
              "          ...,\n",
              "          [ 0.0952, -0.2241, -0.4343,  ..., -0.5555, -0.6643, -0.4893],\n",
              "          [-0.4047, -0.2512, -0.3105,  ..., -0.4566, -0.5259, -0.5010],\n",
              "          [-0.4586, -0.3828, -0.4418,  ..., -0.5335, -0.1554, -0.2210]],\n",
              "\n",
              "         [[ 0.8207,  0.8062,  0.7104,  ...,  0.6693,  0.7019,  0.5416],\n",
              "          [ 0.9648,  0.4394,  0.5721,  ...,  0.6125,  0.6923,  0.8072],\n",
              "          [ 0.7402,  1.1878,  0.7232,  ...,  1.0075,  0.7333,  0.6557],\n",
              "          ...,\n",
              "          [ 0.8998,  0.4625,  0.4729,  ...,  0.6651,  0.9505,  0.6878],\n",
              "          [ 0.8671,  0.5545,  0.4559,  ...,  0.6957,  0.5721,  0.7549],\n",
              "          [ 0.5241,  0.7669,  0.6406,  ...,  1.0009,  0.8587,  0.5802]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.3989, -0.6198, -0.1299,  ..., -0.2082,  0.0019, -0.2825],\n",
              "          [-0.3462, -0.2367, -0.4729,  ..., -0.1284, -0.4043, -0.2997],\n",
              "          [-0.3602, -0.2706, -0.3558,  ..., -0.3985, -0.2982, -0.0568],\n",
              "          ...,\n",
              "          [-0.5630, -0.1744, -0.3773,  ..., -0.2303, -0.0975, -0.2397],\n",
              "          [ 0.0940, -0.0318, -0.6347,  ..., -0.2857, -0.6094, -0.2371],\n",
              "          [-0.3145, -0.1607, -0.3060,  ..., -0.3741, -0.4054, -0.0517]],\n",
              "\n",
              "         [[-0.0923,  0.1302,  0.1457,  ..., -0.1255, -0.1095,  0.0985],\n",
              "          [ 0.0873,  0.0985, -0.1409,  ..., -0.1238, -0.1413, -0.1435],\n",
              "          [-0.1622, -0.1697,  0.0598,  ..., -0.1051,  0.1826,  0.0390],\n",
              "          ...,\n",
              "          [ 0.0912, -0.1020, -0.0966,  ..., -0.1309, -0.0363, -0.1219],\n",
              "          [ 0.3039, -0.0830,  0.1140,  ..., -0.1905, -0.2375,  0.1644],\n",
              "          [ 0.0854, -0.4714,  0.0878,  ...,  0.0965,  0.0269,  0.3337]],\n",
              "\n",
              "         [[-0.3892, -0.3460, -0.2129,  ..., -0.2940, -0.2539, -0.1232],\n",
              "          [-0.2619, -0.2497, -0.2429,  ..., -0.1640, -0.3329, -0.1158],\n",
              "          [-0.3911, -0.1462, -0.3148,  ..., -0.3369, -0.2001, -0.2558],\n",
              "          ...,\n",
              "          [-0.5767, -0.1668, -0.1719,  ..., -0.1886,  0.0168, -0.5220],\n",
              "          [-0.2218, -0.2414, -0.1862,  ...,  0.1958, -0.4700, -0.0792],\n",
              "          [-0.0225, -0.0175,  0.1072,  ...,  0.0149, -0.2746, -0.4145]]]],\n",
              "       grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "rand_tensor = torch.rand(1, 3, 64, 64)\n",
        "\n",
        "\n",
        "conv_layer = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=10,\n",
        "                       kernel_size=3,\n",
        "                       stride=1,\n",
        "                       padding=0) \n",
        "\n",
        "# Pass the data through the convolutional layer\n",
        "conv_layer(rand_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHS20cNTxwSi"
      },
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset. \n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been. \n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error? \n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMUsDcN/+FAm9Pf7Ifqs6AZ",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "udacity_gen_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
